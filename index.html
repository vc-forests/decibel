<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decibel</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h3>Project decibel</h3>
    <button id="startMicrophoneBtn" type="button">Start using microphone</button>
    <button id="stopMicrophoneBtn" type="button" disabled>Stop using microphone</button>
    <script>
        const startMicrophoneBtn = document.getElementById('startMicrophoneBtn');
        const stopMicrophoneBtn = document.getElementById('stopMicrophoneBtn');
        const context = new AudioContext();
        startMicrophoneBtn.addEventListener('click', async function () {
            await initializeAudio();
            stopMicrophoneBtn.disabled = false;
            console.log("Your microphone audio is being used.");
        }, { once: true });
        let micStream;
        async function initializeAudio() {
            // autoplay policy
            if (context.state == "suspended") {
                await context.resume();
            }
            micStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: false,
                    autoGainControl: false,
                    noiseSuppression: false,
                    latency: 0
                }
            })
            // source audio node but for media stream (microphone)
            const micSourceNode = context.createMediaStreamSource(micStream);
            // audio node to adjsut volumne
            const gainNode = new GainNode(context);
            // audio node to analyze audio (frequency analysis)
            const analyserNode = new AnalyserNode(context);
            const recordingProperties = {
                numberOfChannels: micSourceNode.channelCount,
                sampleRate: context.sampleRate,
                maxFrameCount: context.sampleRate * 300
            };
            const recordingNode = await setupRecordingWorkletNode(recordingProperties);
            micSourceNode.connect(recordingNode).connect(context.destination);
        }

        async function setupRecordingWorkletNode(recordingProperties) {
            // Load and execute the module script.
            await context.audioWorklet.addModule('recording-processor.js');
            // Create an AudioWorkletNode. The name of the processor is the
            // one passed to registerProcessor() in the module script.
            const WorkletRecordingNode = new AudioWorkletNode(context, 'recording-processor', {
                processorOptions: recordingProperties
            });
            return WorkletRecordingNode;
        }
    </script>
    <script>
        stopMicrophoneBtn.addEventListener('click', function () {
            // Stop the stream.
            micStream.getTracks().forEach(track => track.stop());
            console.log("Your microphone audio is not used anymore.");
        });
    </script>
</body>

</html>